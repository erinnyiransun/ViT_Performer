{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5P4mtGMeQit"
      },
      "source": [
        "# Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade keras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UCdfSrywKdZY",
        "outputId": "4a11f9e4-8b7b-420d-ac7f-041f9d2a85ed"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Collecting keras\n",
            "  Downloading keras-3.3.3-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras) (1.25.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras) (13.7.1)\n",
            "Collecting namex (from keras)\n",
            "  Downloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras) (3.9.0)\n",
            "Collecting optree (from keras)\n",
            "  Downloading optree-0.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (311 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.2/311.2 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras) (0.2.0)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from optree->keras) (4.11.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
            "Installing collected packages: namex, optree, keras\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.15.0\n",
            "    Uninstalling keras-2.15.0:\n",
            "      Successfully uninstalled keras-2.15.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.3.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed keras-3.3.3 namex-0.0.8 optree-0.11.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "d0aWmaw9eLdt"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"  # @param [\"tensorflow\", \"jax\", \"torch\"]\n",
        "\n",
        "from keras import layers, ops\n",
        "from keras.datasets import mnist\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Dense, Dropout,  Input, Flatten, Layer\n",
        "\n",
        "import math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from keras.callbacks import ModelCheckpoint"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JaDFtB0GgVbB"
      },
      "source": [
        "# Prepare the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "saYdVVEKgTtY",
        "outputId": "e6d71779-712c-434e-e743-f9621b9db27d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "X_train original shape (60000, 28, 28)\n",
            "y_train original shape (60000,)\n",
            "Training matrix shape (60000, 28, 28, 1)\n",
            "Testing matrix shape (10000, 28, 28, 1)\n"
          ]
        }
      ],
      "source": [
        "num_classes = 10\n",
        "input_shape = (28, 28, 1)\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "print(\"X_train original shape\", X_train.shape)\n",
        "print(\"y_train original shape\", y_train.shape)\n",
        "\n",
        "X_train = X_train.reshape(60000, 28,28,1)\n",
        "X_test = X_test.reshape(10000, 28,28,1)\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "print(\"Training matrix shape\", X_train.shape)\n",
        "print(\"Testing matrix shape\", X_test.shape)\n",
        "\n",
        "Y_train = to_categorical(y_train, num_classes)\n",
        "Y_test = to_categorical(y_test, num_classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9QXcMwtNhQWI"
      },
      "source": [
        "# Configure the hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "ty2l7ujthVIE"
      },
      "outputs": [],
      "source": [
        "#learning_rate = 0.001\n",
        "#weight_decay = 0.0001\n",
        "batch_size = 256\n",
        "num_epochs = 3  # For real training, use num_epochs=100. 10 is a test value\n",
        "image_size = 72  # We'll resize input images to this size\n",
        "patch_size = 6  # Size of the patches to be extract from the input images\n",
        "num_patches = (image_size // patch_size) ** 2\n",
        "num_heads = 4\n",
        "d_QK = 16\n",
        "projection_dim = d_QK * num_heads # d, ensure\"encoded_patch, attention output same dim\n",
        "nb_random_features = 16 # m\n",
        "window_size = 12 # to be used in local attention (querying the closest 2 * window_size tokens)\n",
        "transformer_units = [\n",
        "    projection_dim * 2,\n",
        "    projection_dim,\n",
        "]  # Size of the transformer layers\n",
        "transformer_layers = 8\n",
        "mlp_head_units = [\n",
        "    256,\n",
        "    128,\n",
        "]  # Size of the dense layers of the final classifier\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8LBt_H1pgfi"
      },
      "source": [
        "# Data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "nHjS8TsfpgCn"
      },
      "outputs": [],
      "source": [
        "data_augmentation = Sequential(\n",
        "    [\n",
        "        layers.Normalization(),\n",
        "        layers.Resizing(image_size, image_size),\n",
        "        layers.RandomFlip(\"horizontal\"),\n",
        "        layers.RandomRotation(factor=0.02),\n",
        "        layers.RandomZoom(height_factor=0.2, width_factor=0.2),\n",
        "    ],\n",
        "    name=\"data_augmentation\",\n",
        ")\n",
        "# Compute the mean and the variance of the training data for normalization.\n",
        "data_augmentation.layers[0].adapt(X_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "haO5BrdpigIW"
      },
      "source": [
        "#Implement multilayer perceptron (MLP)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "CLYcVK3KilMA"
      },
      "outputs": [],
      "source": [
        "def mlp(x, hidden_units, dropout_rate):\n",
        "    for units in hidden_units:\n",
        "        x = layers.Dense(units, activation='relu')(x)\n",
        "        x = layers.Dropout(dropout_rate)(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hR5CXuqhioFh"
      },
      "source": [
        "# Implement patch creation as a layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "GX8HAOXtisTI"
      },
      "outputs": [],
      "source": [
        "class Patches(layers.Layer):\n",
        "    def __init__(self, patch_size):\n",
        "        super().__init__()\n",
        "        self.patch_size = patch_size\n",
        "\n",
        "    def call(self, images):\n",
        "        input_shape = ops.shape(images)\n",
        "        #input_shape = images.shape\n",
        "        batch_size = input_shape[0]\n",
        "        height = input_shape[1]\n",
        "        width = input_shape[2]\n",
        "        channels = input_shape[3]\n",
        "        num_patches_h = height // self.patch_size\n",
        "        num_patches_w = width // self.patch_size\n",
        "        patches = ops.image.extract_patches(images, size=self.patch_size)\n",
        "        patches = ops.reshape(\n",
        "            patches,\n",
        "            (\n",
        "                batch_size, # sample dimension\n",
        "                num_patches_h * num_patches_w, # patch dimension\n",
        "                self.patch_size * self.patch_size * channels, # patch encoding\n",
        "            ),\n",
        "        )\n",
        "        return patches\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\"patch_size\": self.patch_size})\n",
        "        return config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 762
        },
        "id": "6jahZjzpi9CT",
        "outputId": "e593ecdc-84ef-47bb-c697-f4840a8b94a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 28, 28, 1)\n",
            "Image size: 72 X 72\n",
            "Patch size: 6 X 6\n",
            "Patches per image: 144\n",
            "Elements per patch: 36\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 400x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 400x400 with 144 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# display some patches\n",
        "\n",
        "plt.figure(figsize=(4, 4))\n",
        "image = X_train[np.random.choice(range(X_train.shape[0]))]\n",
        "#plt.imshow(image.astype(\"uint8\"))\n",
        "plt.imshow(image)\n",
        "plt.axis(\"off\")\n",
        "\n",
        "print(ops.convert_to_tensor([image]).shape)\n",
        "resized_image = ops.image.resize(\n",
        "    ops.convert_to_tensor([image]), size=(image_size, image_size)\n",
        ")\n",
        "patches = Patches(patch_size)(resized_image)\n",
        "print(f\"Image size: {image_size} X {image_size}\")\n",
        "print(f\"Patch size: {patch_size} X {patch_size}\")\n",
        "print(f\"Patches per image: {patches.shape[1]}\")\n",
        "print(f\"Elements per patch: {patches.shape[-1]}\")\n",
        "\n",
        "n = int(np.sqrt(patches.shape[1]))\n",
        "plt.figure(figsize=(4, 4))\n",
        "for i, patch in enumerate(patches[0]):\n",
        "    ax = plt.subplot(n, n, i + 1)\n",
        "    patch_img = ops.reshape(patch, (patch_size, patch_size, 1))\n",
        "    #plt.imshow(ops.convert_to_numpy(patch_img).astype(\"uint8\"))\n",
        "    plt.imshow(ops.convert_to_numpy(patch_img))\n",
        "    plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXLR4x21ko8u"
      },
      "source": [
        "# Implement the patch encoding layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "gu7iFCqnktPd"
      },
      "outputs": [],
      "source": [
        "class PatchEncoder(layers.Layer):\n",
        "    def __init__(self, num_patches, projection_dim):\n",
        "        super().__init__()\n",
        "        self.num_patches = num_patches\n",
        "        self.projection = layers.Dense(units=projection_dim)\n",
        "        self.position_embedding = layers.Embedding(\n",
        "            input_dim=num_patches, output_dim=projection_dim\n",
        "        )\n",
        "\n",
        "    def call(self, patch):\n",
        "        positions = ops.expand_dims(\n",
        "            ops.arange(start=0, stop=self.num_patches, step=1), axis=0\n",
        "        )\n",
        "        projected_patches = self.projection(patch)\n",
        "        encoded = projected_patches + self.position_embedding(positions)\n",
        "        return encoded\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\"num_patches\": self.num_patches})\n",
        "        return config"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run ViT Model"
      ],
      "metadata": {
        "id": "jCkmrR7rcwRM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "PG3H7CbxlRvp"
      },
      "outputs": [],
      "source": [
        "def create_vit_classifier():\n",
        "    inputs = Input(shape=input_shape)\n",
        "    # Augment data.\n",
        "    augmented = data_augmentation(inputs)\n",
        "    # Create patches.\n",
        "    patches = Patches(patch_size)(augmented)\n",
        "    # Encode patches.\n",
        "    encoded_patches = PatchEncoder(num_patches, projection_dim)(patches)\n",
        "\n",
        "    # Create multiple layers of the Transformer block.\n",
        "    for _ in range(transformer_layers):\n",
        "        # Layer normalization 1.\n",
        "        x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches) #(N, n_patches, patch_size)\n",
        "        # Create a multi-head attention layer.\n",
        "        #attention_output = layers.MultiHeadAttention(num_heads=num_heads, key_dim=projection_dim, dropout=0.1)(x1, x1)\n",
        "\n",
        "        attention_output = Attention(num_heads = num_heads,\n",
        "                                     hidden_size = projection_dim,\n",
        "                                     attention_dropout = 0.1,\n",
        "                                     kernel_transformation=relu_kernel_transformation,\n",
        "                                     projection_matrix_type = 1,\n",
        "                                     #causal = True,\n",
        "                                     local = True,\n",
        "                                     window_size = window_size,\n",
        "                                     nb_random_features = nb_random_features)(x1, x1, tf.ones([1]))\n",
        "\n",
        "        # Skip connection 1.\n",
        "        x2 = layers.Add()([attention_output, encoded_patches])\n",
        "        # Layer normalization 2.\n",
        "        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
        "        # MLP.\n",
        "        x3 = mlp(x3, hidden_units=transformer_units, dropout_rate=0.1)\n",
        "        # Skip connection 2.\n",
        "        encoded_patches = layers.Add()([x3, x2])\n",
        "\n",
        "    # Create a [batch_size, projection_dim] tensor.\n",
        "    representation = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
        "    representation = layers.Flatten()(representation)\n",
        "    representation = layers.Dropout(0.5)(representation)\n",
        "    # Add MLP.\n",
        "    features = mlp(representation, hidden_units=mlp_head_units, dropout_rate=0.5)\n",
        "    # Classify outputs.\n",
        "    #logits = layers.Dense(num_classes)(features)\n",
        "    outputs = layers.Dense(num_classes, activation='softmax')(features)\n",
        "    # Create the Keras model.\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 636
        },
        "id": "b1pXF-yymN7C",
        "outputId": "43d1cde4-bd1c-4f02-cf6d-e9c7807fe317"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1011s\u001b[0m 3s/step - accuracy: 0.4106 - loss: 1.9720 - val_accuracy: 0.8248 - val_loss: 0.5746\n",
            "Epoch 2/3\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m620s\u001b[0m 3s/step - accuracy: 0.6883 - loss: 0.9630 - val_accuracy: 0.8900 - val_loss: 0.3706\n",
            "Epoch 3/3\n",
            "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m623s\u001b[0m 3s/step - accuracy: 0.7699 - loss: 0.6902 - val_accuracy: 0.9187 - val_loss: 0.3048\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 160ms/step - accuracy: 0.8875 - loss: 0.3560\n",
            "Test accuracy: 90.6%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "def run_experiment(model):\n",
        "    #optimizer = keras.optimizers.AdamW(\n",
        "        #learning_rate=learning_rate, weight_decay=weight_decay\n",
        "    #)\n",
        "\n",
        "    model.compile(\n",
        "        #optimizer=optimizer,\n",
        "        optimizer = 'adam',\n",
        "        #loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "        loss = 'categorical_crossentropy',\n",
        "        metrics=[\n",
        "            'accuracy'\n",
        "            #keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\"),\n",
        "            #keras.metrics.SparseTopKCategoricalAccuracy(5, name=\"top-5-accuracy\"),\n",
        "        ],\n",
        "    )\n",
        "\n",
        "    checkpoint_filepath = \"/tmp/checkpoint.weights.h5\"\n",
        "    checkpoint_callback = ModelCheckpoint(\n",
        "        checkpoint_filepath,\n",
        "        monitor=\"val_accuracy\",\n",
        "        save_best_only=True,\n",
        "        save_weights_only=True,\n",
        "    )\n",
        "\n",
        "    history = model.fit(\n",
        "        x=X_train,\n",
        "        y=Y_train,\n",
        "        batch_size=batch_size,\n",
        "        epochs=num_epochs,\n",
        "        validation_split=0.1,\n",
        "        callbacks=[checkpoint_callback],\n",
        "    )\n",
        "\n",
        "    model.load_weights(checkpoint_filepath)\n",
        "    #_, accuracy, top_5_accuracy = model.evaluate(X_test, y_test)\n",
        "    _, accuracy = model.evaluate(X_test, Y_test)\n",
        "    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
        "    #print(f\"Test top 5 accuracy: {round(top_5_accuracy * 100, 2)}%\")\n",
        "\n",
        "    return history\n",
        "\n",
        "\n",
        "vit_classifier = create_vit_classifier()\n",
        "history = run_experiment(vit_classifier)\n",
        "\n",
        "\n",
        "def plot_history(item):\n",
        "    plt.plot(history.history[item], label=item)\n",
        "    plt.plot(history.history[\"val_\" + item], label=\"val_\" + item)\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(item)\n",
        "    plt.title(\"Train and Validation {} Over Epochs\".format(item), fontsize=14)\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "plot_history(\"loss\")\n",
        "#plot_history(\"top-5-accuracy\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FAST_ATTENTION"
      ],
      "metadata": {
        "id": "zFMvxOaXlAdg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BIG_CONSTANT = 1e8\n",
        "\n",
        "\n",
        "def create_projection_matrix(m, d, seed=0, scaling=0, struct_mode=False):\n",
        "  r\"\"\"Constructs the matrix of random projections.\n",
        "\n",
        "  Constructs a matrix of random orthogonal projections. Each projection vector\n",
        "  has direction chosen uniformly at random and either deterministic length\n",
        "  \\sqrt{d} or length taken from the \\chi(d) distribution (in the latter case\n",
        "  marginal distributions of the projections are d-dimensional Gaussian vectors\n",
        "  with associated identity covariance matrix).\n",
        "\n",
        "  Args:\n",
        "    m: number of random projections.\n",
        "    d: dimensionality of each random projection.\n",
        "    seed: random seed used to construct projections.\n",
        "    scaling: 1 if all the random projections need to be renormalized to have\n",
        "      length \\sqrt{d}, 0 if the lengths of random projections should follow\n",
        "      \\chi(d) distribution.\n",
        "    struct_mode: if True then products of Givens rotations will be used to\n",
        "      construct random orthogonal matrix. This bypasses Gram-Schmidt\n",
        "      orthogonalization.\n",
        "\n",
        "  Returns:\n",
        "    The matrix of random projections of the shape [m, d].\n",
        "  \"\"\"\n",
        "  nb_full_blocks = int(m / d)\n",
        "  block_list = []\n",
        "  current_seed = seed\n",
        "  for _ in range(nb_full_blocks):\n",
        "    if struct_mode:\n",
        "      q = create_products_of_givens_rotations(d, seed)\n",
        "    else:\n",
        "      unstructured_block = tf.random.normal((d, d), seed=current_seed)\n",
        "      q, _ = tf.linalg.qr(unstructured_block)\n",
        "      q = tf.transpose(q)\n",
        "    block_list.append(q)\n",
        "    current_seed += 1\n",
        "  remaining_rows = m - nb_full_blocks * d\n",
        "  if remaining_rows > 0:\n",
        "    if struct_mode:\n",
        "      q = create_products_of_givens_rotations(d, seed)\n",
        "    else:\n",
        "      unstructured_block = tf.random.normal((d, d), seed=current_seed)\n",
        "      q, _ = tf.linalg.qr(unstructured_block)\n",
        "      q = tf.transpose(q)\n",
        "    block_list.append(q[0:remaining_rows])\n",
        "  final_matrix = tf.experimental.numpy.vstack(block_list)\n",
        "  current_seed += 1\n",
        "\n",
        "  if scaling == 0:\n",
        "    multiplier = tf.norm(tf.random.normal((m, d), seed=current_seed), axis=1)\n",
        "  elif scaling == 1:\n",
        "    multiplier = tf.math.sqrt(float(d)) * tf.ones((m))\n",
        "  else:\n",
        "    raise ValueError(\"Scaling must be one of {0, 1}. Was %s\" % scaling)\n",
        "\n",
        "  return tf.linalg.matmul(tf.linalg.diag(multiplier), final_matrix)\n",
        "\n",
        "\n",
        "def create_products_of_givens_rotations(dim, seed):\n",
        "  r\"\"\"Constructs a 2D-tensor which is a product of Givens random rotations.\n",
        "\n",
        "  Constructs a 2D-tensor of the form G_1 * ... * G_k, where G_i is a Givens\n",
        "  random rotation. The resulting tensor mimics a matrix taken uniformly at\n",
        "  random form the orthogonal group.\n",
        "\n",
        "  Args:\n",
        "    dim: number of rows/columns of the resulting 2D-tensor.\n",
        "    seed: random seed.\n",
        "\n",
        "  Returns:\n",
        "    The product of Givens random rotations.\n",
        "  \"\"\"\n",
        "  nb_givens_rotations = dim * int(math.ceil(math.log(float(dim))))\n",
        "  q = np.eye(dim, dim)\n",
        "  np.random.seed(seed)\n",
        "  for _ in range(nb_givens_rotations):\n",
        "    random_angle = math.pi * np.random.uniform()\n",
        "    random_indices = np.random.choice(dim, 2)\n",
        "    index_i = min(random_indices[0], random_indices[1])\n",
        "    index_j = max(random_indices[0], random_indices[1])\n",
        "    slice_i = q[index_i]\n",
        "    slice_j = q[index_j]\n",
        "    new_slice_i = math.cos(random_angle) * slice_i + math.sin(\n",
        "        random_angle) * slice_j\n",
        "    new_slice_j = -math.sin(random_angle) * slice_i + math.cos(\n",
        "        random_angle) * slice_j\n",
        "    q[index_i] = new_slice_i\n",
        "    q[index_j] = new_slice_j\n",
        "  return tf.cast(tf.constant(q), dtype=tf.float32)\n",
        "\n",
        "\n",
        "def relu_kernel_transformation(data,\n",
        "                               is_query,\n",
        "                               projection_matrix=None,\n",
        "                               numerical_stabilizer=0.001):\n",
        "  \"\"\"Computes features for the ReLU-kernel.\n",
        "\n",
        "  Computes random features for the ReLU kernel from\n",
        "  https://arxiv.org/pdf/2009.14794.pdf.\n",
        "\n",
        "  Args:\n",
        "    data: input data tensor of the shape [B, L, H, D], where: B - batch\n",
        "      dimension, L - attention dimensions, H - heads, D - features.\n",
        "    is_query: indicates whether input data is a query oor key tensor.\n",
        "    projection_matrix: random Gaussian matrix of shape [M, D], where M stands\n",
        "      for the number of random features and each D x D sub-block has pairwise\n",
        "      orthogonal rows.\n",
        "    numerical_stabilizer: small positive constant for numerical stability.\n",
        "\n",
        "  Returns:\n",
        "    Corresponding kernel feature map.\n",
        "  \"\"\"\n",
        "  del is_query\n",
        "  if projection_matrix is None:\n",
        "    return tf.nn.relu(data) + numerical_stabilizer\n",
        "  else:\n",
        "    ratio = 1.0 / tf.math.sqrt(\n",
        "        tf.dtypes.cast(projection_matrix.shape[0], tf.float32))\n",
        "    data_dash = ratio * tf.einsum(\"blhd,md->blhm\", data, projection_matrix)\n",
        "    return tf.nn.relu(data_dash) + numerical_stabilizer\n",
        "\n",
        "\n",
        "def softmax_kernel_transformation(data,\n",
        "                                  is_query,\n",
        "                                  projection_matrix=None,\n",
        "                                  numerical_stabilizer=0.000001):\n",
        "  \"\"\"Computes random features for the softmax kernel using FAVOR+ mechanism.\n",
        "\n",
        "  Computes random features for the softmax kernel using FAVOR+ mechanism from\n",
        "  https://arxiv.org/pdf/2009.14794.pdf.\n",
        "\n",
        "  Args:\n",
        "    data: input data tensor of the shape [B, L, H, D], where: B - batch\n",
        "      dimension, L - attention dimensions, H - heads, D - features.\n",
        "    is_query: indicates whether input data is a query oor key tensor.\n",
        "    projection_matrix: random Gaussian matrix of shape [M, D], where M stands\n",
        "      for the number of random features and each D x D sub-block has pairwise\n",
        "      orthogonal rows.\n",
        "    numerical_stabilizer: small positive constant for numerical stability.\n",
        "\n",
        "  Returns:\n",
        "    Corresponding kernel feature map.\n",
        "  \"\"\"\n",
        "  data_normalizer = 1.0 / (\n",
        "      tf.math.sqrt(tf.math.sqrt(tf.dtypes.cast(data.shape[-1], tf.float32))))\n",
        "  data = data_normalizer * data\n",
        "  ratio = 1.0 / tf.math.sqrt(\n",
        "      tf.dtypes.cast(projection_matrix.shape[0], tf.float32))\n",
        "  data_dash = tf.einsum(\"blhd,md->blhm\", data, projection_matrix)\n",
        "  diag_data = tf.math.square(data)\n",
        "  diag_data = tf.math.reduce_sum(\n",
        "      diag_data, axis=tf.keras.backend.ndim(data) - 1)\n",
        "  diag_data = diag_data / 2.0\n",
        "  diag_data = tf.expand_dims(diag_data, axis=tf.keras.backend.ndim(data) - 1)\n",
        "  last_dims_t = (len(data_dash.shape) - 1,)\n",
        "  attention_dims_t = (len(data_dash.shape) - 3,)\n",
        "  if is_query:\n",
        "    data_dash = ratio * (\n",
        "        tf.math.exp(data_dash - diag_data - tf.math.reduce_max(\n",
        "            data_dash, axis=last_dims_t, keepdims=True)) + numerical_stabilizer)\n",
        "  else:\n",
        "    data_dash = ratio * (\n",
        "        tf.math.exp(data_dash - diag_data - tf.math.reduce_max(\n",
        "            data_dash, axis=last_dims_t + attention_dims_t, keepdims=True)) +\n",
        "        numerical_stabilizer)\n",
        "\n",
        "  return data_dash\n",
        "\n",
        "\n",
        "def noncausal_numerator(qs, ks, vs):\n",
        "  \"\"\"Computes not-normalized FAVOR noncausal attention AV.\n",
        "\n",
        "  Args:\n",
        "    qs: query_prime tensor of the shape [L,B,H,M].\n",
        "    ks: key_prime tensor of the shape [L,B,H,M].\n",
        "    vs: value tensor of the shape [L,B,H,D].\n",
        "\n",
        "  Returns:\n",
        "    Not-normalized FAVOR noncausal attention AV.\n",
        "  \"\"\"\n",
        "  kvs = tf.einsum(\"lbhm,lbhd->bhmd\", ks, vs)\n",
        "  return tf.einsum(\"lbhm,bhmd->lbhd\", qs, kvs)\n",
        "\n",
        "\n",
        "def noncausal_denominator(qs, ks):\n",
        "  \"\"\"Computes FAVOR normalizer in noncausal attention.\n",
        "\n",
        "  Args:\n",
        "    qs: query_prime tensor of the shape [L,B,H,M].\n",
        "    ks: key_prime tensor of the shape [L,B,H,M].\n",
        "\n",
        "  Returns:\n",
        "    FAVOR normalizer in noncausal attention.\n",
        "  \"\"\"\n",
        "  all_ones = tf.ones([ks.shape[0]])\n",
        "  ks_sum = tf.einsum(\"lbhm,l->bhm\", ks, all_ones)\n",
        "  return tf.einsum(\"lbhm,bhm->lbh\", qs, ks_sum)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "@tf.custom_gradient\n",
        "def causal_numerator(qs, ks, vs):\n",
        "  \"\"\"Computes not-normalized FAVOR causal attention A_{masked}V.\n",
        "\n",
        "  Args:\n",
        "    qs: query_prime tensor of the shape [L,B,H,M].\n",
        "    ks: key_prime tensor of the shape [L,B,H,M].\n",
        "    vs: value tensor of the shape [L,B,H,D].\n",
        "\n",
        "  Returns:\n",
        "    Not-normalized FAVOR causal attention A_{masked}V.\n",
        "  \"\"\"\n",
        "\n",
        "  result = []\n",
        "  sums = tf.zeros_like(tf.einsum(\"ijk,ijl->ijkl\", ks[0], vs[0])) #(B, H, M, D)\n",
        "  #ks[0] shape (None, num_heads, m)\n",
        "\n",
        "  for index in range(qs.shape[0]):\n",
        "    sums = sums + tf.einsum(\"ijk,ijl->ijkl\", ks[index], vs[index])\n",
        "    result.append(tf.einsum(\"ijkl,ijk->ijl\", sums, qs[index])[None, Ellipsis])\n",
        "\n",
        "  result = tf.concat(result, axis=0)\n",
        "\n",
        "  def grad(res_grad):\n",
        "\n",
        "    grads = tf.zeros_like(tf.einsum(\"ijk,ijl->ijkl\", ks[0], vs[0]))\n",
        "\n",
        "    gr_sums = sums\n",
        "\n",
        "    q_grads = []\n",
        "    k_grads = []\n",
        "    v_grads = []\n",
        "\n",
        "    for index in range(qs.shape[0] - 1, -1, -1):\n",
        "\n",
        "      q_grads.append(\n",
        "          tf.einsum(\"ijkl,ijl->ijk\", gr_sums, res_grad[index])[None, Ellipsis])\n",
        "      grads = grads + tf.einsum(\"ijk,ijl->ijkl\", qs[index], res_grad[index])\n",
        "      k_grads.append(tf.einsum(\"ijkl,ijl->ijk\", grads, vs[index])[None, Ellipsis])\n",
        "      v_grads.append(tf.einsum(\"ijkl,ijk->ijl\", grads, ks[index])[None, Ellipsis])\n",
        "      gr_sums = gr_sums - tf.einsum(\"ijk,ijl->ijkl\", ks[index], vs[index])\n",
        "\n",
        "    q_grads = tf.concat(q_grads[::-1], axis=0)\n",
        "    k_grads = tf.concat(k_grads[::-1], axis=0)\n",
        "    v_grads = tf.concat(v_grads[::-1], axis=0)\n",
        "\n",
        "    return q_grads, k_grads, v_grads\n",
        "\n",
        "  return result, grad\n",
        "\n",
        "\n",
        "@tf.custom_gradient\n",
        "def causal_denominator(qs, ks):\n",
        "  \"\"\"Computes FAVOR normalizer in causal attention.\n",
        "\n",
        "  Args:\n",
        "    qs: query_prime tensor of the shape [L,B,H,M].\n",
        "    ks: key_prime tensor of the shape [L,B,H,M].\n",
        "\n",
        "  Returns:\n",
        "    FAVOR normalizer in causal attention.\n",
        "  \"\"\"\n",
        "\n",
        "  result = []\n",
        "  sums = tf.zeros_like(ks[0])\n",
        "\n",
        "  for index in range(qs.shape[0]):\n",
        "    sums = sums + ks[index]\n",
        "    result.append(tf.reduce_sum(qs[index] * sums, axis=2)[None, Ellipsis])\n",
        "\n",
        "  result = tf.concat(result, axis=0)\n",
        "\n",
        "  def grad(res_grad):\n",
        "\n",
        "    k_grad = tf.zeros_like(ks[0])\n",
        "\n",
        "    gr_sums = sums\n",
        "\n",
        "    q_grads = []\n",
        "    k_grads = []\n",
        "\n",
        "    for index in range(qs.shape[0] - 1, -1, -1):\n",
        "\n",
        "      q_grads.append(tf.einsum(\"ijk,ij->ijk\", gr_sums, res_grad[index])[None, Ellipsis])\n",
        "      k_grad = k_grad + tf.einsum(\"ijk,ij->ijk\", qs[index], res_grad[index])\n",
        "      k_grads.append(k_grad[None, Ellipsis])\n",
        "      gr_sums = gr_sums - ks[index]\n",
        "\n",
        "    q_grads = tf.concat(q_grads[::-1], axis=0)\n",
        "    k_grads = tf.concat(k_grads[::-1], axis=0)\n",
        "\n",
        "    return q_grads, k_grads\n",
        "\n",
        "  return result, grad\n",
        "\n",
        "\n",
        "@tf.custom_gradient\n",
        "def local_numerator(qs, ks, vs):\n",
        "  \"\"\"Computes not-normalized FAVOR local attention A_{masked}V.\n",
        "\n",
        "  Args:\n",
        "    qs: query_prime tensor of the shape [L,B,H,M].\n",
        "    ks: key_prime tensor of the shape [L,B,H,M].\n",
        "    vs: value tensor of the shape [L,B,H,D].\n",
        "    implicit window_size\n",
        "\n",
        "  Returns:\n",
        "    Not-normalized FAVOR local attention A_{masked}V.\n",
        "  \"\"\"\n",
        "\n",
        "  result = []\n",
        "\n",
        "  tmp = []\n",
        "  for index in range(qs.shape[0]):\n",
        "    tmp.append(tf.expand_dims(tf.einsum(\"ijk,ijl->ijkl\", ks[index], vs[index]), axis = 0))\n",
        "  tmp = tf.concat(tmp, axis = 0)\n",
        "\n",
        "  sums = tf.reduce_sum(tmp[:window_size + 1], axis = 0)\n",
        "  for index in range(qs.shape[0]):\n",
        "    result.append(tf.einsum(\"ijkl,ijk->ijl\", sums, qs[index])[None, Ellipsis])\n",
        "    if index + window_size + 1 < qs.shape[0]:\n",
        "      sums = sums + tmp[index + window_size + 1]\n",
        "    if index - window_size >= 0:\n",
        "      sums = sums - tmp[index - window_size]\n",
        "\n",
        "  '''\n",
        "  mask = [True] * (window_size + 1) + [False] * (qs.shape[0] - window_size - 1)\n",
        "  mask = np.array(mask)\n",
        "  for index in range(qs.shape[0]):\n",
        "    sums = tf.boolean_mask(tmp, mask, axis = 0)\n",
        "    sums = tf.reduce_sum(sums, axis = 0)\n",
        "    if index + window_size + 1 < qs.shape[0]:\n",
        "      mask[index + window_size + 1] = True\n",
        "    if index - window_size >= 0:\n",
        "      mask[index - window_size] = False\n",
        "    result.append(tf.einsum(\"ijkl,ijk->ijl\", sums, qs[index])[None, Ellipsis])\n",
        "  '''\n",
        "\n",
        "  result = tf.concat(result, axis=0)\n",
        "\n",
        "  def grad(res_grad):\n",
        "\n",
        "    q_grads = []\n",
        "    k_grads = []\n",
        "    v_grads = []\n",
        "\n",
        "    tmp = []\n",
        "    for index in range(qs.shape[0]):\n",
        "      tmp.append(tf.expand_dims(tf.einsum(\"ijk,ijl->ijkl\", ks[index], vs[index]), axis = 0))\n",
        "    tmp = tf.concat(tmp, axis = 0)\n",
        "\n",
        "    # q grads\n",
        "    sums = tf.reduce_sum(tmp[:window_size + 1], axis = 0)\n",
        "    for index in range(qs.shape[0]):\n",
        "      q_grads.append(tf.einsum(\"ijkl,ijl->ijk\", sums, res_grad[index])[None, Ellipsis])\n",
        "      if index + window_size + 1 < qs.shape[0]:\n",
        "        sums = sums + tmp[index + window_size + 1]\n",
        "      if index - window_size >= 0:\n",
        "        sums = sums - tmp[index - window_size]\n",
        "\n",
        "    # k and v grads\n",
        "    tmp = []\n",
        "    for index in range(qs.shape[0]):\n",
        "      tmp.append(tf.expand_dims(tf.einsum(\"ijk,ijl->ijkl\", qs[index], res_grad[index]), axis = 0))\n",
        "    tmp = tf.concat(tmp, axis = 0)\n",
        "\n",
        "    sums = tf.reduce_sum(tmp[:window_size + 1], axis = 0)\n",
        "    for index in range(qs.shape[0]):\n",
        "      k_grads.append(tf.einsum(\"ijkl,ijl->ijk\", sums, vs[index])[None, Ellipsis])\n",
        "      v_grads.append(tf.einsum(\"ijkl,ijk->ijl\", sums, ks[index])[None, Ellipsis])\n",
        "      if index + window_size + 1 < qs.shape[0]:\n",
        "        sums = sums + tmp[index + window_size + 1]\n",
        "      if index - window_size >= 0:\n",
        "        sums = sums - tmp[index - window_size]\n",
        "\n",
        "\n",
        "    '''\n",
        "    # q grads, assume tmp stays the way it is\n",
        "    mask = [True] * (window_size + 1) + [False] * (qs.shape[0] - window_size - 1)\n",
        "    mask = np.array(mask)\n",
        "    for index in range(qs.shape[0]):\n",
        "      sums = tf.boolean_mask(tmp, mask, axis = 0)\n",
        "      sums = tf.reduce_sum(sums, axis = 0)\n",
        "      if index + window_size + 1 < qs.shape[0]:\n",
        "        mask[index + window_size + 1] = True\n",
        "      if index - window_size >= 0:\n",
        "        mask[index - window_size] = False\n",
        "      q_grads.append(tf.einsum(\"ijkl,ijl->ijk\", sums, res_grad[index])[None, Ellipsis])\n",
        "\n",
        "    # k and v grads\n",
        "    tmp = []\n",
        "    for index in range(qs.shape[0]):\n",
        "      tmp.append(tf.expand_dims(tf.einsum(\"ijk,ijl->ijkl\", qs[index], res_grad[index]), axis = 0))\n",
        "    tmp = tf.concat(tmp, axis = 0)\n",
        "\n",
        "    mask = [True] * (window_size + 1) + [False] * (qs.shape[0] - window_size - 1)\n",
        "    mask = np.array(mask)\n",
        "    for index in range(qs.shape[0]):\n",
        "      sums = tf.boolean_mask(tmp, mask, axis = 0)\n",
        "      sums = tf.reduce_sum(sums, axis = 0)\n",
        "      if index + window_size + 1 < qs.shape[0]:\n",
        "        mask[index + window_size + 1] = True\n",
        "      if index - window_size >= 0:\n",
        "        mask[index - window_size] = False\n",
        "      k_grads.append(tf.einsum(\"ijkl,ijl->ijk\", sums, vs[index])[None, Ellipsis])\n",
        "      v_grads.append(tf.einsum(\"ijkl,ijk->ijl\", sums, ks[index])[None, Ellipsis])\n",
        "\n",
        "    '''\n",
        "\n",
        "    q_grads = tf.concat(q_grads, axis=0)\n",
        "    k_grads = tf.concat(k_grads, axis=0)\n",
        "    v_grads = tf.concat(v_grads, axis=0)\n",
        "\n",
        "    return q_grads, k_grads, v_grads\n",
        "\n",
        "  return result, grad\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "@tf.custom_gradient\n",
        "def local_denominator(qs, ks):\n",
        "  \"\"\"Computes FAVOR normalizer in causal attention.\n",
        "\n",
        "  Args:\n",
        "    qs: query_prime tensor of the shape [L,B,H,M].\n",
        "    ks: key_prime tensor of the shape [L,B,H,M].\n",
        "\n",
        "  Returns:\n",
        "    FAVOR normalizer in causal attention.\n",
        "  \"\"\"\n",
        "\n",
        "  result = []\n",
        "\n",
        "  sums = tf.reduce_sum(ks[:window_size + 1], axis = 0)\n",
        "  for index in range(qs.shape[0]):\n",
        "    result.append(tf.reduce_sum(qs[index] * sums, axis=2)[None, Ellipsis])\n",
        "    if index + window_size + 1 < qs.shape[0]:\n",
        "      sums = sums + ks[index + window_size + 1]\n",
        "    if index - window_size >= 0:\n",
        "      sums = sums - ks[index - window_size]\n",
        "\n",
        "  result = tf.concat(result, axis=0)\n",
        "\n",
        "  def grad(res_grad):\n",
        "\n",
        "    q_grads = []\n",
        "    k_grads = []\n",
        "\n",
        "    # q grads\n",
        "    sums = tf.reduce_sum(ks[:window_size + 1], axis = 0)\n",
        "    for index in range(qs.shape[0]):\n",
        "      q_grads.append(tf.einsum(\"ijk,ij->ijk\", sums, res_grad[index])[None, Ellipsis])\n",
        "      if index + window_size + 1 < qs.shape[0]:\n",
        "        sums = sums + ks[index + window_size + 1]\n",
        "      if index - window_size >= 0:\n",
        "        sums = sums - ks[index - window_size]\n",
        "\n",
        "    # k grads\n",
        "    tmp = []\n",
        "    for index in range(qs.shape[0]):\n",
        "      tmp.append(tf.expand_dims(tf.einsum(\"ijk,ij->ijk\", qs[index], res_grad[index]), axis = 0))\n",
        "    tmp = tf.concat(tmp, axis = 0)\n",
        "\n",
        "    sums = tf.reduce_sum(tmp[:window_size + 1], axis = 0)\n",
        "    for index in range(qs.shape[0]):\n",
        "      k_grads.append(sums[None, Ellipsis])\n",
        "      if index + window_size + 1 < qs.shape[0]:\n",
        "        sums = sums + tmp[index + window_size + 1]\n",
        "      if index - window_size >= 0:\n",
        "        sums = sums - tmp[index - window_size]\n",
        "\n",
        "    \"\"\"\n",
        "    for index in range(qs.shape[0] - 1, -1, -1):\n",
        "\n",
        "      q_grads.append(tf.einsum(\"ijk,ij->ijk\", gr_sums, res_grad[index])[None, Ellipsis])\n",
        "      k_grad = k_grad + tf.einsum(\"ijk,ij->ijk\", qs[index], res_grad[index])\n",
        "      k_grads.append(k_grad[None, Ellipsis])\n",
        "      gr_sums = gr_sums - ks[index]\n",
        "    \"\"\"\n",
        "\n",
        "    q_grads = tf.concat(q_grads, axis=0)\n",
        "    k_grads = tf.concat(k_grads, axis=0)\n",
        "\n",
        "    return q_grads, k_grads\n",
        "\n",
        "  return result, grad\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def favor_attention(query,\n",
        "                    key,\n",
        "                    value,\n",
        "                    kernel_transformation,\n",
        "                    causal,\n",
        "                    local=False,\n",
        "                    window_size=None,\n",
        "                    projection_matrix=None):\n",
        "  \"\"\"Computes FAVOR normalized attention.\n",
        "\n",
        "  Args:\n",
        "    query: query tensor.\n",
        "    key: key tensor.\n",
        "    value: value tensor.\n",
        "    kernel_transformation: transformation used to get finite kernel features.\n",
        "    causal: whether attention is causal or not.\n",
        "    projection_matrix: projection matrix to be used.\n",
        "\n",
        "  Returns:\n",
        "    FAVOR normalized attention.\n",
        "  \"\"\"\n",
        "  query_prime = kernel_transformation(query, True,\n",
        "                                      projection_matrix)  # [B,L,H,M]\n",
        "  key_prime = kernel_transformation(key, False, projection_matrix)  # [B,L,H,M]\n",
        "  query_prime = tf.transpose(query_prime, [1, 0, 2, 3])  # [L,B,H,M]\n",
        "  key_prime = tf.transpose(key_prime, [1, 0, 2, 3])  # [L,B,H,M]\n",
        "  value = tf.transpose(value, [1, 0, 2, 3])  # [L,B,H,D]\n",
        "\n",
        "  if causal:\n",
        "    av_attention = causal_numerator(query_prime, key_prime, value)\n",
        "    attention_normalizer = causal_denominator(query_prime, key_prime)\n",
        "  elif local:\n",
        "    av_attention = local_numerator(query_prime, key_prime, value)\n",
        "    attention_normalizer = local_denominator(query_prime, key_prime)\n",
        "  else:\n",
        "    av_attention = noncausal_numerator(query_prime, key_prime, value)\n",
        "    attention_normalizer = noncausal_denominator(query_prime, key_prime)\n",
        "  # TODO(kchoro): Add more comments.\n",
        "  av_attention = tf.transpose(av_attention, [1, 0, 2, 3])\n",
        "  attention_normalizer = tf.transpose(attention_normalizer, [1, 0, 2])\n",
        "  attention_normalizer = tf.expand_dims(attention_normalizer,\n",
        "                                        len(attention_normalizer.shape))\n",
        "  return av_attention / attention_normalizer\n",
        "\n",
        "\n",
        "class Attention(tf.keras.layers.Layer):\n",
        "  \"\"\"Multi-headed attention layer.\"\"\"\n",
        "\n",
        "  def __init__(self,\n",
        "               hidden_size,\n",
        "               num_heads,\n",
        "               attention_dropout,\n",
        "               kernel_transformation=relu_kernel_transformation,\n",
        "               numerical_stabilizer=0.001,\n",
        "               causal=False,\n",
        "               local=False,\n",
        "               window_size=None,\n",
        "               projection_matrix_type=None,\n",
        "               nb_random_features=0):\n",
        "\n",
        "    \"\"\"Initialize Attention.\n",
        "\n",
        "    Args:\n",
        "      hidden_size: int, output dim of hidden layer.\n",
        "      num_heads: int, number of heads to repeat the same attention structure.\n",
        "      attention_dropout: float, dropout rate inside attention for training.\n",
        "      kernel_transformation: transformation used to produce kernel features for\n",
        "        attention.\n",
        "      numerical_stabilizer: used to bound away from zero kernel values.\n",
        "      causal: whether attention is causal or not.\n",
        "      projection_matrix_type: None if Identity should be used, otherwise random\n",
        "        projection matrix will be applied.\n",
        "      nb_random_features: number of random features to be used (relevant only if\n",
        "        projection_matrix is not None).\n",
        "    \"\"\"\n",
        "    if hidden_size % num_heads:\n",
        "      raise ValueError(\n",
        "          \"Hidden size ({}) must be divisible by the number of heads ({}).\"\n",
        "          .format(hidden_size, num_heads))\n",
        "\n",
        "    super(Attention, self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.num_heads = num_heads\n",
        "    self.attention_dropout = attention_dropout\n",
        "    self.kernel_transformation = kernel_transformation\n",
        "    self.numerical_stabilizer = numerical_stabilizer\n",
        "    self.causal = causal\n",
        "    self.local = local\n",
        "    self.window_size = window_size\n",
        "    self.projection_matrix_type = projection_matrix_type\n",
        "    self.nb_random_features = nb_random_features\n",
        "\n",
        "  def build(self, input_shape):\n",
        "    \"\"\"Builds the layer.\"\"\"\n",
        "    # Layers for linearly projecting the queries, keys, and values.\n",
        "    size_per_head = self.hidden_size // self.num_heads\n",
        "\n",
        "    def _glorot_initializer(fan_in, fan_out):\n",
        "      limit = math.sqrt(6.0 / (fan_in + fan_out))\n",
        "      return tf.keras.initializers.RandomUniform(minval=-limit, maxval=limit)\n",
        "\n",
        "    #if isinstance(input_shape, tuple):\n",
        "        #attention_initializer = _glorot_initializer(input_shape[-1], self.hidden_size)\n",
        "    #else:\n",
        "        #attention_initializer = _glorot_initializer(input_shape.as_list()[-1], self.hidden_size)\n",
        "    attention_initializer = _glorot_initializer(input_shape[-1], self.hidden_size) #ADDED\n",
        "\n",
        "    self.query_dense_layer = DenseEinsum(\n",
        "        output_shape=(self.num_heads, size_per_head),\n",
        "        kernel_initializer=attention_initializer,\n",
        "        use_bias=False,\n",
        "        name=\"query\")\n",
        "    self.key_dense_layer = DenseEinsum(\n",
        "        output_shape=(self.num_heads, size_per_head),\n",
        "        kernel_initializer=attention_initializer,\n",
        "        use_bias=False,\n",
        "        name=\"key\")\n",
        "    self.value_dense_layer = DenseEinsum(\n",
        "        output_shape=(self.num_heads, size_per_head),\n",
        "        kernel_initializer=attention_initializer,\n",
        "        use_bias=False,\n",
        "        name=\"value\")\n",
        "\n",
        "    output_initializer = _glorot_initializer(self.hidden_size, self.hidden_size)\n",
        "    self.output_dense_layer = DenseEinsum(\n",
        "        output_shape=self.hidden_size,\n",
        "        num_summed_dimensions=2,\n",
        "        kernel_initializer=output_initializer,\n",
        "        use_bias=False,\n",
        "        name=\"output_transform\")\n",
        "    super(Attention, self).build(input_shape)\n",
        "\n",
        "  def get_config(self):\n",
        "    return {\n",
        "        \"hidden_size\": self.hidden_size,\n",
        "        \"num_heads\": self.num_heads,\n",
        "        \"attention_dropout\": self.attention_dropout,\n",
        "    }\n",
        "\n",
        "  def call(self,\n",
        "           query_input,\n",
        "           source_input,\n",
        "           bias,\n",
        "           training = None,\n",
        "           cache=None,\n",
        "           decode_loop_step=None):\n",
        "    \"\"\"Apply attention mechanism to query_input and source_input.\n",
        "\n",
        "    Args:\n",
        "      query_input: A tensor with shape [batch_size, length_query, hidden_size].\n",
        "      source_input: A tensor with shape [batch_size, length_source,\n",
        "        hidden_size].\n",
        "      bias: A tensor with shape [batch_size, 1, length_query, length_source],\n",
        "        the attention bias that will be added to the result of the dot product.\n",
        "      training: A bool, whether in training mode or not.\n",
        "      cache: (Used during prediction) A dictionary with tensors containing\n",
        "        results of previous attentions. The dictionary must have the items:\n",
        "            {\"k\": tensor with shape [batch_size, i, heads, dim_per_head],\n",
        "             \"v\": tensor with shape [batch_size, i, heads, dim_per_head]} where\n",
        "               i is the current decoded length for non-padded decode, or max\n",
        "               sequence length for padded decode.\n",
        "      decode_loop_step: An integer, step number of the decoding loop. Used only\n",
        "        for autoregressive inference on TPU.\n",
        "\n",
        "    Returns:\n",
        "      Attention layer output with shape [batch_size, length_query, hidden_size]\n",
        "    \"\"\"\n",
        "    # Linearly project the query, key and value using different learned\n",
        "    # projections. Splitting heads is automatically done during the linear\n",
        "    # projections --> [batch_size, length, num_heads, dim_per_head].\n",
        "    query = self.query_dense_layer(query_input)\n",
        "    key = self.key_dense_layer(source_input)\n",
        "    value = self.value_dense_layer(source_input)\n",
        "\n",
        "    if self.projection_matrix_type is None:\n",
        "      projection_matrix = None\n",
        "    else:\n",
        "      dim = query.shape[-1]\n",
        "      #seed = tf.math.ceil(tf.math.abs(tf.math.reduce_sum(query) * BIG_CONSTANT))\n",
        "      #seed = tf.cast(seed, tf.int32)\n",
        "      seed = 10000 # ADDED because tf.random.normal does not take tf.tensor as seed\n",
        "      #print('seed is:', seed, type(seed))\n",
        "      projection_matrix = create_projection_matrix(\n",
        "          self.nb_random_features, dim, seed=seed)\n",
        "\n",
        "    if cache is not None:\n",
        "      # Combine cached keys and values with new keys and values.\n",
        "      if decode_loop_step is not None:\n",
        "        cache_k_shape = cache[\"k\"].shape.as_list()\n",
        "        indices = tf.reshape(\n",
        "            tf.one_hot(decode_loop_step, cache_k_shape[1], dtype=key.dtype),\n",
        "            [1, cache_k_shape[1], 1, 1])\n",
        "        key = cache[\"k\"] + key * indices\n",
        "        cache_v_shape = cache[\"v\"].shape.as_list()\n",
        "        indices = tf.reshape(\n",
        "            tf.one_hot(decode_loop_step, cache_v_shape[1], dtype=value.dtype),\n",
        "            [1, cache_v_shape[1], 1, 1])\n",
        "        value = cache[\"v\"] + value * indices\n",
        "      else:\n",
        "        key = tf.concat([tf.cast(cache[\"k\"], key.dtype), key], axis=1)\n",
        "        value = tf.concat([tf.cast(cache[\"v\"], value.dtype), value], axis=1)\n",
        "\n",
        "      # Update cache\n",
        "      cache[\"k\"] = key\n",
        "      cache[\"v\"] = value\n",
        "\n",
        "    attention_output = favor_attention(query, key, value,\n",
        "                                       self.kernel_transformation, self.causal,\n",
        "                                       self.local, self.window_size,\n",
        "                                       projection_matrix)\n",
        "    attention_output = self.output_dense_layer(attention_output)\n",
        "    return attention_output\n",
        "\n",
        "\n",
        "class SelfAttention(Attention):\n",
        "  \"\"\"Multiheaded self-attention layer.\"\"\"\n",
        "\n",
        "  def call(self,\n",
        "           query_input,\n",
        "           bias,\n",
        "           training = None,\n",
        "           cache=None,\n",
        "           decode_loop_step=None):\n",
        "    return super(SelfAttention, self).call(query_input, query_input, bias,\n",
        "                                           training, cache, decode_loop_step)\n"
      ],
      "metadata": {
        "id": "-Vc7eSNGlCqf"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# UTILS"
      ],
      "metadata": {
        "id": "Yr9LjkuQk7AC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "_CHR_IDX = [\"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\", \"h\", \"i\", \"j\", \"k\", \"l\", \"m\"]\n",
        "\n",
        "\n",
        "@tf.keras.utils.register_keras_serializable(package=\"Text\")\n",
        "class DenseEinsum(Layer):\n",
        "  \"\"\"A densely connected layer that uses tf.einsum as the backing computation.\n",
        "\n",
        "  This layer can perform einsum calculations of arbitrary dimensionality.\n",
        "\n",
        "  Arguments:\n",
        "    output_shape: Positive integer or tuple, dimensionality of the output space.\n",
        "    num_summed_dimensions: The number of dimensions to sum over. Standard 2D\n",
        "      matmul should use 1, 3D matmul should use 2, and so forth.\n",
        "    activation: Activation function to use. If you don't specify anything, no\n",
        "      activation is applied\n",
        "      (ie. \"linear\" activation: `a(x) = x`).\n",
        "    use_bias: Boolean, whether the layer uses a bias vector.\n",
        "    kernel_initializer: Initializer for the `kernel` weights matrix.\n",
        "    bias_initializer: Initializer for the bias vector.\n",
        "    kernel_regularizer: Regularizer function applied to the `kernel` weights\n",
        "      matrix.\n",
        "    bias_regularizer: Regularizer function applied to the bias vector.\n",
        "    activity_regularizer: Regularizer function applied to the output of the\n",
        "      layer (its \"activation\")..\n",
        "    kernel_constraint: Constraint function applied to the `kernel` weights\n",
        "      matrix.\n",
        "    bias_constraint: Constraint function applied to the bias vector.\n",
        "  Input shape:\n",
        "    N-D tensor with shape: `(batch_size, ..., input_dim)`. The most common\n",
        "      situation would be a 2D input with shape `(batch_size, input_dim)`.\n",
        "  Output shape:\n",
        "    N-D tensor with shape: `(batch_size, ..., units)`. For instance, for a 2D\n",
        "      input with shape `(batch_size, input_dim)`, the output would have shape\n",
        "      `(batch_size, units)`.\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self,\n",
        "               output_shape,\n",
        "               num_summed_dimensions=1,\n",
        "               activation=None,\n",
        "               use_bias=True,\n",
        "               kernel_initializer=\"glorot_uniform\",\n",
        "               bias_initializer=\"zeros\",\n",
        "               kernel_regularizer=None,\n",
        "               bias_regularizer=None,\n",
        "               activity_regularizer=None,\n",
        "               kernel_constraint=None,\n",
        "               bias_constraint=None,\n",
        "               **kwargs):\n",
        "    super(DenseEinsum, self).__init__(**kwargs)\n",
        "    self._output_shape = output_shape if isinstance(\n",
        "        output_shape, (list, tuple)) else (output_shape,)\n",
        "    self._activation = tf.keras.activations.get(activation)\n",
        "    self._use_bias = use_bias\n",
        "    self._kernel_initializer = tf.keras.initializers.get(kernel_initializer)\n",
        "    self._bias_initializer = tf.keras.initializers.get(bias_initializer)\n",
        "    self._kernel_regularizer = tf.keras.regularizers.get(kernel_regularizer)\n",
        "    self._bias_regularizer = tf.keras.regularizers.get(bias_regularizer)\n",
        "    self._kernel_constraint = tf.keras.constraints.get(kernel_constraint)\n",
        "    self._bias_constraint = tf.keras.constraints.get(bias_constraint)\n",
        "    self._num_summed_dimensions = num_summed_dimensions\n",
        "    self._einsum_string = None\n",
        "\n",
        "  def _build_einsum_string(self, free_input_dims, bound_dims, output_dims):\n",
        "    input_str = \"\"\n",
        "    kernel_str = \"\"\n",
        "    output_str = \"\"\n",
        "    letter_offset = 0\n",
        "    for i in range(free_input_dims):\n",
        "      char = _CHR_IDX[i + letter_offset]\n",
        "      input_str += char\n",
        "      output_str += char\n",
        "\n",
        "    letter_offset += free_input_dims\n",
        "    for i in range(bound_dims):\n",
        "      char = _CHR_IDX[i + letter_offset]\n",
        "      input_str += char\n",
        "      kernel_str += char\n",
        "\n",
        "    letter_offset += bound_dims\n",
        "    for i in range(output_dims):\n",
        "      char = _CHR_IDX[i + letter_offset]\n",
        "      kernel_str += char\n",
        "      output_str += char\n",
        "\n",
        "    return input_str + \",\" + kernel_str + \"->\" + output_str\n",
        "\n",
        "  def build(self, input_shape):\n",
        "    input_shape = tf.TensorShape(input_shape)\n",
        "    input_rank = input_shape.rank\n",
        "    free_input_dims = input_rank - self._num_summed_dimensions\n",
        "    output_dims = len(self._output_shape)\n",
        "\n",
        "    self._einsum_string = self._build_einsum_string(free_input_dims,\n",
        "                                                    self._num_summed_dimensions,\n",
        "                                                    output_dims)\n",
        "\n",
        "    # This is only saved for testing purposes.\n",
        "    self._kernel_shape = (\n",
        "        input_shape[free_input_dims:].concatenate(self._output_shape))\n",
        "\n",
        "    self._kernel = self.add_weight(\n",
        "        name=\"kernel\",\n",
        "        shape=self._kernel_shape,\n",
        "        initializer=self._kernel_initializer,\n",
        "        regularizer=self._kernel_regularizer,\n",
        "        constraint=self._kernel_constraint,\n",
        "        dtype=self.dtype,\n",
        "        trainable=True)\n",
        "\n",
        "    if self._use_bias:\n",
        "      self._bias = self.add_weight(\n",
        "          name=\"bias\",\n",
        "          #shape=self._output_shape,\n",
        "          initializer=self._bias_initializer,\n",
        "          regularizer=self._bias_regularizer,\n",
        "          constraint=self._bias_constraint,\n",
        "          dtype=self.dtype,\n",
        "          trainable=True)\n",
        "    else:\n",
        "      self._bias = None\n",
        "    super(DenseEinsum, self).build(input_shape)\n",
        "\n",
        "  def get_config(self):\n",
        "    config = {\n",
        "        \"output_shape\":\n",
        "            self._output_shape,\n",
        "        \"num_summed_dimensions\":\n",
        "            self._num_summed_dimensions,\n",
        "        \"activation\":\n",
        "            tf.keras.activations.serialize(self._activation),\n",
        "        \"use_bias\":\n",
        "            self._use_bias,\n",
        "        \"kernel_initializer\":\n",
        "            tf.keras.initializers.serialize(self._kernel_initializer),\n",
        "        \"bias_initializer\":\n",
        "            tf.keras.initializers.serialize(self._bias_initializer),\n",
        "        \"kernel_regularizer\":\n",
        "            tf.keras.regularizers.serialize(self._kernel_regularizer),\n",
        "        \"bias_regularizer\":\n",
        "            tf.keras.regularizers.serialize(self._bias_regularizer),\n",
        "        \"activity_regularizer\":\n",
        "            tf.keras.regularizers.serialize(self._activity_regularizer),\n",
        "        \"kernel_constraint\":\n",
        "            tf.keras.constraints.serialize(self._kernel_constraint),\n",
        "        \"bias_constraint\":\n",
        "            tf.keras.constraints.serialize(self._bias_constraint)\n",
        "    }\n",
        "    base_config = super(DenseEinsum, self).get_config()\n",
        "    return dict(list(base_config.items()) + list(config.items()))\n",
        "\n",
        "  def call(self, inputs):\n",
        "    ret = tf.einsum(self._einsum_string, inputs, self._kernel)\n",
        "    if self._use_bias:\n",
        "      ret += self._bias\n",
        "    if self._activation is not None:\n",
        "      ret = self._activation(ret)\n",
        "    return ret\n"
      ],
      "metadata": {
        "id": "vH5TMDa1k6bU"
      },
      "execution_count": 13,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}